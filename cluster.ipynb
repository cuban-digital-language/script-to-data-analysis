{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dany/.local/share/virtualenvs/cuba-digital-lang-9Kd57kqM/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from vectorize import load, length\n",
    "from tools import get_progressbar\n",
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[########################################] 162474 scatter matrix computing 100%\n"
     ]
    }
   ],
   "source": [
    "_len_ = length('texts')\n",
    "bar = get_progressbar(_len_, f' {_len_} scatter matrix computing ')\n",
    "\n",
    "frame = dict([(f'x{i}', []) for i in range(96)])\n",
    "vectors = []\n",
    "vectors_to_text = {}\n",
    "bar.start()\n",
    "for i, tuple_ in enumerate(load('texts')):\n",
    "    if len(tuple_[1]) > 0:\n",
    "        vectors.append(np.array(tuple_[1]))\n",
    "        vectors_to_text[tuple_[1]] = tuple_[0]\n",
    "\n",
    "    for i, comp in enumerate(tuple_[1]):\n",
    "        frame[f'x{i}'].append(comp)\n",
    "\n",
    "    bar.update(i+1)\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pandas.DataFrame(frame)\n",
    "\n",
    "# df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.plotting.scatter_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "vector = preprocessing.normalize(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 1\n",
      "Estimated number of noise points: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/dany/src/school/cuba-digital-lang/script_to_data_analysis/cluster.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/cuba-digital-lang/script_to_data_analysis/cluster.ipynb#ch0000006?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEstimated number of noise points: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m n_noise_)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/cuba-digital-lang/script_to_data_analysis/cluster.ipynb#ch0000006?line=15'>16</a>\u001b[0m \u001b[39m# print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/cuba-digital-lang/script_to_data_analysis/cluster.ipynb#ch0000006?line=16'>17</a>\u001b[0m \u001b[39m# print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/cuba-digital-lang/script_to_data_analysis/cluster.ipynb#ch0000006?line=17'>18</a>\u001b[0m \u001b[39m# print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/cuba-digital-lang/script_to_data_analysis/cluster.ipynb#ch0000006?line=21'>22</a>\u001b[0m \u001b[39m#     % metrics.adjusted_mutual_info_score(labels_true, labels)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/cuba-digital-lang/script_to_data_analysis/cluster.ipynb#ch0000006?line=22'>23</a>\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/dany/src/school/cuba-digital-lang/script_to_data_analysis/cluster.ipynb#ch0000006?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSilhouette Coefficient: \u001b[39m\u001b[39m%0.3f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m metrics\u001b[39m.\u001b[39;49msilhouette_score(vector, labels))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/cuba-digital-lang-9Kd57kqM/lib/python3.9/site-packages/sklearn/metrics/cluster/_unsupervised.py:117\u001b[0m, in \u001b[0;36msilhouette_score\u001b[0;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         X, labels \u001b[39m=\u001b[39m X[indices], labels[indices]\n\u001b[0;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(silhouette_samples(X, labels, metric\u001b[39m=\u001b[39;49mmetric, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/cuba-digital-lang-9Kd57kqM/lib/python3.9/site-packages/sklearn/metrics/cluster/_unsupervised.py:231\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    229\u001b[0m n_samples \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(labels)\n\u001b[1;32m    230\u001b[0m label_freqs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(labels)\n\u001b[0;32m--> 231\u001b[0m check_number_of_labels(\u001b[39mlen\u001b[39;49m(le\u001b[39m.\u001b[39;49mclasses_), n_samples)\n\u001b[1;32m    233\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m metric\n\u001b[1;32m    234\u001b[0m reduce_func \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m    235\u001b[0m     _silhouette_reduce, labels\u001b[39m=\u001b[39mlabels, label_freqs\u001b[39m=\u001b[39mlabel_freqs\n\u001b[1;32m    236\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/cuba-digital-lang-9Kd57kqM/lib/python3.9/site-packages/sklearn/metrics/cluster/_unsupervised.py:33\u001b[0m, in \u001b[0;36mcheck_number_of_labels\u001b[0;34m(n_labels, n_samples)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m    Number of samples.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m n_labels \u001b[39m<\u001b[39m n_samples:\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNumber of labels is \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. Valid values are 2 to n_samples - 1 (inclusive)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m         \u001b[39m%\u001b[39m n_labels\n\u001b[1;32m     36\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "\n",
    "db = DBSCAN(eps=0.8, min_samples=10, metric='cosine', n_jobs=10).fit(vector)\n",
    "# core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "# core_samples_mask[db.core_sample_indices_] = True\n",
    "\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "# print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "# print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "# print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "# print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\n",
    "# print(\n",
    "#     \"Adjusted Mutual Information: %0.3f\"\n",
    "#     % metrics.adjusted_mutual_info_score(labels_true, labels)\n",
    "# )\n",
    "print(\"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(vector, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import DistanceMetric, kneighbors_graph\n",
    "import matplotlib.pyplot as plt\n",
    "dist = DistanceMetric.get_metric('manhattan')\n",
    "matsim = dist.pairwise(vector)\n",
    "minPits = 5\n",
    "A = kneighbors_graph(vector, minPits, include_self=False).toarray()\n",
    "\n",
    "seq = []\n",
    "for i, s in enumerate(vector):\n",
    "    for j in range(len(vector)):\n",
    "        if A[i][j] != 0:\n",
    "            seq.append(matsim[i][j])\n",
    "    \n",
    "seq.sort()\n",
    "plt.plot(seq)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(inertials):\n",
    "    x, y = zip(*[inertia for inertia in inertials])\n",
    "    plt.plot(x, y, 'ro-', markersize=8, lw=2)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Num Clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def select_clusters(loops, max_iterations, init_cluster, tolerance,\n",
    "                    num_threads):\n",
    "    # Read data set\n",
    "    points = vectors\n",
    "\n",
    "    inertia_clusters = list()\n",
    "\n",
    "    for i in range(1, loops + 1, 1):\n",
    "        # Object KMeans\n",
    "        kmeans = KMeans(n_clusters=i, max_iter=max_iterations,\n",
    "                        init=init_cluster, tol=tolerance, n_jobs=num_threads)\n",
    "\n",
    "        # Calculate Kmeans\n",
    "        kmeans.fit(points)\n",
    "\n",
    "        # Obtain inertia\n",
    "        inertia_clusters.append([i, kmeans.inertia_])\n",
    "\n",
    "    plot_results(inertia_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "select_clusters(10, 1000, \"k-means++\", 0.001, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('cuba-digital-lang-9Kd57kqM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "603d3262a7e4ed4b0851c01fdb7ddd10a0cced451adaee2bc5b3533b94fd096e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
